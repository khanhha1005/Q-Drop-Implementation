{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc3GWn_jojsG"
      },
      "source": [
        "# MNIST notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXpH5753pfZU"
      },
      "source": [
        "## import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "DG-wTTncnnjX"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel 'Pennylane (Python 3.11.10)'. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOSPC: no space left on device, write"
          ]
        }
      ],
      "source": [
        "import os\n",
        "# Set TensorFlow logging to only show errors\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # This silences INFO and WARNING messages\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Add, Dense, Dropout, Embedding, GlobalAveragePooling1D, Input, Layer, LayerNormalization, MultiHeadAttention\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "\n",
        "try:\n",
        "  import pennylane as qml\n",
        "except:\n",
        "  !pip install pennylane\n",
        "  import pennylane as qml\n",
        "from pennylane.operation import Operation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oa2gttKppTU"
      },
      "source": [
        "## Import the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Vr_vMdH-FlP",
        "outputId": "3238e9ed-36db-40d5-a7b8-c5cc0917030c"
      },
      "outputs": [],
      "source": [
        "# !pip install medmnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "t9VleEId-FW2"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "# Set the random seeds for reproducibility\n",
        "random_seed = 40  # You can choose any seed number\n",
        "\n",
        "# Set the random seed for Python's built-in random module\n",
        "random.seed(random_seed)\n",
        "\n",
        "# Set the random seed for NumPy\n",
        "np.random.seed(random_seed)\n",
        "\n",
        "# Set the random seed for TensorFlow\n",
        "tf.random.set_seed(random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Filter for only the classes 3 and 6\n",
        "train_filter = np.where((y_train == 6) | (y_train == 3))\n",
        "test_filter = np.where((y_test == 6) | (y_test == 3))\n",
        "\n",
        "x_train, y_train = x_train[train_filter], y_train[train_filter]\n",
        "x_test, y_test = x_test[test_filter], y_test[test_filter]\n",
        "\n",
        "# Use the first 500 images as the training set\n",
        "x_train, y_train = x_train[:500], y_train[:500]\n",
        "# Randomly sample 300 images from the remaining data as the validation set\n",
        "x_val, y_val = x_test[500:800], y_test[500:800]\n",
        "\n",
        "x_test, y_test = x_test[:300], y_test[:300]\n",
        "\n",
        "# Rescale the images\n",
        "x_train = x_train / 255.0\n",
        "x_val = x_val / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "print(\"Training set shape:\", x_train.shape)\n",
        "print(\"Validation set shape:\", x_val.shape)\n",
        "print(\"Test set shape:\", x_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot a random sample of 16 images from the training set\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(16):\n",
        "    plt.subplot(4, 4, i+1)\n",
        "    plt.imshow(x_train[i], cmap='gray')\n",
        "    plt.title(y_train[i])  # Assuming y_train contains the class labels\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOpfOZc3bKF8"
      },
      "outputs": [],
      "source": [
        "# Expand the dimensions of the images to (28, 28, 1) to represent the grayscale channel explicitly\n",
        "\n",
        "train_images = np.expand_dims(x_train, -1)\n",
        "validation_images = np.expand_dims(x_val, -1)\n",
        "test_images = np.expand_dims(x_test, -1)\n",
        "\n",
        "# Map the labels 3 -> 0 and 6 -> 1\n",
        "y_train_binary = np.where(y_train == 3, 0, 1)\n",
        "y_val_binary = np.where(y_val == 3, 0, 1)\n",
        "y_test_binary = np.where(y_test == 3, 0, 1)\n",
        "\n",
        "# Convert the labels to one-hot encoded vectors\n",
        "train_labels = to_categorical(y_train_binary, 2)\n",
        "validation_labels = to_categorical(y_val_binary, 2)\n",
        "test_labels = to_categorical(y_test_binary, 2)\n",
        "\n",
        "print(\"Shape of train labels:\", train_labels.shape)\n",
        "print(\"Shape of validation labels:\", validation_labels.shape)\n",
        "print(\"Shape of test labels:\", test_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXdj0ZilYdII",
        "outputId": "469ad37f-d244-40ff-b1d2-4d3c86e63bce"
      },
      "outputs": [],
      "source": [
        "unique_labels = np.unique(y_train)\n",
        "print(f\"Unique labels in the training set: {unique_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "DQ4cCjAJqaIZ"
      },
      "outputs": [],
      "source": [
        "def plot_images(images, labels, num_images=25, figsize=(10,10)):\n",
        "    grid_size = 5\n",
        "    plt.figure(figsize=figsize)\n",
        "\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(grid_size, grid_size, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        plt.imshow(images[i], cmap='gray')\n",
        "        plt.xlabel(f'Label: {labels[i]}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ryf3e3L6GKj"
      },
      "source": [
        "## Common Quantum functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "K7mK4jvaa_RS"
      },
      "outputs": [],
      "source": [
        "class RBSGate(Operation):\n",
        "    num_params = 1\n",
        "    num_wires = 2\n",
        "    par_domain = 'R'\n",
        "\n",
        "    def __init__(self, theta, wires):\n",
        "        super().__init__(theta, wires=wires)\n",
        "        self.theta = theta\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_matrix(theta):\n",
        "        cos = tf.cos(theta)\n",
        "        sin = tf.sin(theta)\n",
        "        return tf.convert_to_tensor([\n",
        "            [1, 0, 0, 0],\n",
        "            [0, cos, sin, 0],\n",
        "            [0, -sin, cos, 0],\n",
        "            [0, 0, 0, 1]\n",
        "        ], dtype=tf.float64)\n",
        "\n",
        "    def adjoint(self):\n",
        "        return RBSGate(-self.parameters[0], wires=self.wires)\n",
        "\n",
        "    def label(self, decimals=None, base_label=None, **kwargs):\n",
        "        theta = self.parameters[0]\n",
        "        return f\"RBS({theta:.2f})\"\n",
        "def convert_array(X):\n",
        "    alphas = tf.zeros(X.shape[:-1] + (X.shape[-1]-1,), dtype=X.dtype)\n",
        "    X_normd = tf.linalg.l2_normalize(X, axis=-1)\n",
        "    for i in range(X.shape[-1]-1):\n",
        "        prod_sin_alphas = tf.reduce_prod(tf.sin(alphas[..., :i]), axis=-1)\n",
        "        updated_value = tf.acos(X_normd[..., i] / prod_sin_alphas)\n",
        "        indices = tf.constant([[i]])\n",
        "        updates = tf.reshape(updated_value, [1])\n",
        "        alphas = tf.tensor_scatter_nd_update(alphas, indices, updates)\n",
        "    return alphas\n",
        "def vector_loader(alphas, wires=None, is_x=True, is_conjugate=False):\n",
        "    if wires is None:\n",
        "        wires = list(range(len(alphas) + 1))\n",
        "    if is_x and not is_conjugate:\n",
        "        qml.PauliX(wires=wires[0])\n",
        "    if is_conjugate:\n",
        "        for i in range(len(wires) - 2, -1, -1):\n",
        "            qml.apply(RBSGate(-alphas[i], wires=[wires[i], wires[i+1]]))\n",
        "    else:\n",
        "        for i in range(len(wires) - 1):\n",
        "            qml.apply(RBSGate(alphas[i], wires=[wires[i], wires[i+1]]))\n",
        "    if is_x and is_conjugate:\n",
        "        qml.PauliX(wires=wires[0])\n",
        "def pyramid_circuit(parameters, wires=None):\n",
        "    if wires is None:\n",
        "        length = len(qml.device.wires)\n",
        "    else:\n",
        "        length = len(wires)\n",
        "\n",
        "    k = 0\n",
        "\n",
        "    for i in range(2 * length - 2):\n",
        "        j = length - abs(length - 1 - i)\n",
        "\n",
        "        if i % 2:\n",
        "            for _ in range(j):\n",
        "                if _ % 2 == 0 and k < (parameters.shape[0]):\n",
        "                    qml.apply(RBSGate(parameters[k], wires=([wires[_], wires[_ + 1]])))\n",
        "                    k += 1\n",
        "        else:\n",
        "            for _ in range(j):\n",
        "                if _ % 2 and k < (parameters.shape[0]):\n",
        "                    qml.apply(RBSGate(parameters[k], wires=([wires[_], wires[_ + 1]])))\n",
        "                    k += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caklx0-k6RHm"
      },
      "source": [
        "# qOrthNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "6AXTsrKB6Uui"
      },
      "outputs": [],
      "source": [
        "class HybridModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(HybridModel, self).__init__()\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.dense = tf.keras.layers.Dense(6, activation='linear', dtype=tf.float64)\n",
        "        self.quantum_weights = self.add_weight(\n",
        "            shape=(15,),\n",
        "            initializer='zeros',\n",
        "            trainable=True,\n",
        "            dtype=tf.float32\n",
        "        )\n",
        "        self.dev = qml.device('default.qubit.tf', wires=6)\n",
        "        # Pruning attributes\n",
        "        self.accumulated_grads = tf.Variable(tf.zeros_like(self.quantum_weights), trainable=False)\n",
        "        self.accumulate_window = 6\n",
        "        self.prune_window = 7\n",
        "        self.prune_ratio = 0.8\n",
        "\n",
        "        @qml.qnode(self.dev, interface='tf', diff_method='backprop')\n",
        "        def quantum_circuit(inputs, weights):\n",
        "            inputs = tf.cast(inputs, tf.float32)\n",
        "            weights = tf.cast(weights, tf.float32)\n",
        "            vector_loader(convert_array(inputs), wires=range(6))\n",
        "            pyramid_circuit(weights, wires=range(6))\n",
        "            return [qml.expval(qml.PauliZ(wire)) for wire in range(6)]\n",
        "\n",
        "        self.quantum_circuit = quantum_circuit\n",
        "        # self.classical_nn_1 = tf.keras.layers.Dense(6, activation='relu', dtype=tf.float64)\n",
        "        self.classical_nn_2 = tf.keras.layers.Dense(2, activation='softmax', dtype=tf.float64)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        inputs = tf.cast(inputs, tf.float64)\n",
        "        flattened_inputs = self.flatten(inputs)\n",
        "        classical_output = self.dense(flattened_inputs)\n",
        "        quantum_outputs = tf.map_fn(\n",
        "            lambda x: tf.stack(self.quantum_circuit(x, self.quantum_weights)),\n",
        "            classical_output,\n",
        "            fn_output_signature=tf.TensorSpec(shape=(6,), dtype=tf.float64)\n",
        "        )\n",
        "        # Handle NaN values in quantum outputs\n",
        "        quantum_outputs = tf.where(tf.math.is_nan(quantum_outputs), tf.zeros_like(quantum_outputs), quantum_outputs)\n",
        "\n",
        "        # Combine and process quantum outputs through additional NN layers\n",
        "        quantum_outputs = tf.reshape(quantum_outputs, [-1, 6])\n",
        "        # nn_output = self.classical_nn_1(quantum_outputs)\n",
        "        nn_output = self.classical_nn_2(quantum_outputs)\n",
        "\n",
        "        return nn_output\n",
        "    def train_step(self, data):\n",
        "        x, y = data  # Unpack the data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Forward pass\n",
        "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "\n",
        "        # Compute gradients\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "\n",
        "        # Find the index of quantum_weights in trainable_variables\n",
        "        for idx, var in enumerate(self.trainable_variables):\n",
        "            if var is self.quantum_weights:\n",
        "                quantum_weights_idx = idx\n",
        "                break\n",
        "\n",
        "        # Probabilistic Gradient Pruning\n",
        "        # Step 1: Accumulate gradients for quantum_weights\n",
        "        if self.accumulate_window > 0:\n",
        "            if gradients[quantum_weights_idx] is not None:\n",
        "                self.accumulated_grads.assign_add(gradients[quantum_weights_idx])\n",
        "            self.accumulate_window -= 1\n",
        "\n",
        "            # Apply gradients for other variables (excluding quantum_weights)\n",
        "            other_gradients = []\n",
        "            other_variables = []\n",
        "            for i, (grad, var) in enumerate(zip(gradients, self.trainable_variables)):\n",
        "                if i != quantum_weights_idx and grad is not None:\n",
        "                    other_gradients.append(grad)\n",
        "                    other_variables.append(var)\n",
        "            self.optimizer.apply_gradients(zip(other_gradients, other_variables))\n",
        "        else:\n",
        "            # Step 2: Prune weights of quantum_weights\n",
        "            # Normalize the accumulated gradients\n",
        "            grad_min = tf.reduce_min(self.accumulated_grads)\n",
        "            grad_max = tf.reduce_max(self.accumulated_grads)\n",
        "            epsilon = 1e-8\n",
        "            norm_grads = (self.accumulated_grads - grad_min) / (grad_max - grad_min + epsilon)\n",
        "\n",
        "            # Add epsilon to norm_grads to avoid log(0)\n",
        "            norm_grads_with_epsilon = norm_grads + epsilon\n",
        "\n",
        "            # Compute logits for categorical sampling\n",
        "            logits = tf.math.log(norm_grads_with_epsilon)\n",
        "\n",
        "            # Determine the number of parameters to sample\n",
        "            num_params = self.quantum_weights.shape[0]\n",
        "            num_samples = int(self.prune_ratio * num_params)\n",
        "            num_samples = max(1, num_samples)  # Ensure at least one parameter is sampled\n",
        "\n",
        "            # Sample indices based on the normalized gradients\n",
        "            indices = tf.random.categorical([logits], num_samples=num_samples)\n",
        "            indices = tf.squeeze(indices, axis=0)\n",
        "\n",
        "            # Create a boolean mask to select the parameters to keep\n",
        "            mask = tf.zeros_like(self.quantum_weights, dtype=tf.bool)\n",
        "            indices = tf.cast(indices, tf.int32)\n",
        "            mask = tf.tensor_scatter_nd_update(\n",
        "                mask, tf.expand_dims(indices, axis=1), tf.ones_like(indices, dtype=tf.bool)\n",
        "            )\n",
        "\n",
        "            # Apply the mask to the accumulated gradients\n",
        "            pruned_grad = tf.where(mask, self.accumulated_grads[0], tf.zeros_like(self.accumulated_grads[0]))\n",
        "\n",
        "            # Apply the pruned gradient to quantum_weights\n",
        "            self.optimizer.apply_gradients([(pruned_grad, self.quantum_weights)])\n",
        "\n",
        "            # Apply gradients for other variables (excluding quantum_weights)\n",
        "            other_gradients = []\n",
        "            other_variables = []\n",
        "            for i, (grad, var) in enumerate(zip(gradients, self.trainable_variables)):\n",
        "                if i != quantum_weights_idx and grad is not None:\n",
        "                    other_gradients.append(grad)\n",
        "                    other_variables.append(var)\n",
        "            self.optimizer.apply_gradients(zip(other_gradients, other_variables))\n",
        "\n",
        "            # Reset accumulator and accumulate window\n",
        "            self.accumulated_grads.assign(tf.zeros_like(self.accumulated_grads))\n",
        "            self.accumulate_window = 10  # Reset the accumulate window\n",
        "\n",
        "        # Sanitize weights: replace NaNs with zeros\n",
        "        for var in self.trainable_variables:\n",
        "            # Create a mask where NaNs are present\n",
        "            nan_mask = tf.math.is_nan(var)\n",
        "            # Replace NaNs with zeros\n",
        "            sanitized_var = tf.where(nan_mask, tf.zeros_like(var), var)\n",
        "            # Assign the sanitized variable back to the model\n",
        "            var.assign(sanitized_var)\n",
        "\n",
        "        # Update metrics\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "\n",
        "        # Return a dictionary of metric results\n",
        "        return {m.name: m.result() for m in self.metrics}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "id": "AOExJJhB6VGK"
      },
      "outputs": [],
      "source": [
        "model = HybridModel()\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFyy7jBj6i11",
        "outputId": "85e1ea1f-d3c9-496d-8ff6-8b4e88b1e452"
      },
      "outputs": [],
      "source": [
        "# Start training\n",
        "history = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_data=(validation_images, validation_labels)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDTVOZnA6kyN",
        "outputId": "6569895a-4607-4889-9d7b-2933b9339b3d"
      },
      "outputs": [],
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "oLp6JV81Yj51"
      },
      "outputs": [],
      "source": [
        "# 20/20 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - accuracy: 0.8541 - auc: 0.9117 - loss: 0.4013\n",
        "# Test Loss: 0.3863230347633362\n",
        "# Test Accuracy: 0.8461538553237915\n",
        "# Test AUC: 0.9197215437889099"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Loss: 0.4583341181278229\n",
        "# Test Accuracy: 0.8166666626930237\n",
        "# Test AUC: 0.8569444417953491"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "uXpH5753pfZU"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Pennylane",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
